{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lacykaltgr/hworldmodel/blob/main/coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08uJsb1T-QyH",
        "outputId": "25a2cd2b-2733-4944-9d49-081ab2e8acb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchrl\n",
            "  Downloading torchrl-0.3.1-cp310-cp310-manylinux1_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Collecting tensordict>=0.3.1 (from torchrl)\n",
            "  Downloading tensordict-0.3.2-cp310-cp310-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=2.1.0 (from torchrl)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->torchrl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->torchrl)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->torchrl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, tensordict, torchrl\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 tensordict-0.3.2 torch-2.2.2 torchrl-0.3.1\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->tensordict) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->tensordict) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->tensordict) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchrl\n",
        "!pip install tensordict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Awl-Xhf17wiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import tempfile\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchrl.collectors import MultiaSyncDataCollector\n",
        "from torchrl.data import LazyMemmapStorage, MultiStep, TensorDictReplayBuffer\n",
        "from torchrl.envs import (\n",
        "    EnvCreator,\n",
        "    ExplorationType,\n",
        "    ParallelEnv,\n",
        "    RewardScaling,\n",
        "    StepCounter,\n",
        ")\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.transforms import (\n",
        "    FrameSkipTransform,\n",
        "    CatFrames,\n",
        "    Compose,\n",
        "    GrayScale,\n",
        "    ObservationNorm,\n",
        "    Resize,\n",
        "    ToTensorImage,\n",
        "    TransformedEnv,\n",
        ")\n",
        "\n",
        "from torchrl.record.loggers.csv import CSVLogger\n",
        "from torchrl.trainers import (\n",
        "    LogReward,\n",
        "    Recorder,\n",
        "    ReplayBufferTrainer,\n",
        "    Trainer,\n",
        "    UpdateWeights,\n",
        ")\n",
        "\n",
        "from torchrl.modules import (\n",
        "    MLP,\n",
        "    SafeModule,\n",
        "    SafeProbabilisticModule,\n",
        "    SafeProbabilisticTensorDictSequential,\n",
        "    SafeSequential\n",
        ")\n",
        "from tensordict import TensorDict\n",
        "from tensordict.nn import TensorDictModuleBase, TensorDictSequential, TensorDictModule\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from torchrl.modules.distributions import IndependentNormal, TanhNormal\n",
        "from torchrl.envs.transforms.transforms import TensorDictPrimer\n",
        "from torchrl.data.tensor_specs import UnboundedContinuousTensorSpec\n",
        "from torchrl.modules.models.model_based import ObsEncoder, ObsDecoder\n",
        "from tensordict.utils import NestedKey\n",
        "from torchrl.objectives.common import LossModule\n",
        "from torchrl.collectors.collectors import RandomPolicy\n",
        "\n",
        "\n",
        "def is_notebook() -> bool:\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        if shell == \"ZMQInteractiveShell\":\n",
        "            return True  # Jupyter notebook or qtconsole\n",
        "        elif shell == \"TerminalInteractiveShell\":\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other type (?)\n",
        "    except NameError:\n",
        "        return False  # Probably standard Python interpreter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgX_Nc827wiO"
      },
      "source": [
        "Let's get started with the various pieces we need for our algorithm:\n",
        "\n",
        "- An environment;\n",
        "- A policy (and related modules that we group under the \"model\" umbrella);\n",
        "- A data collector, which makes the policy play in the environment and\n",
        "  delivers training data;\n",
        "- A replay buffer to store the training data;\n",
        "- A loss module, which computes the objective function to train our policy\n",
        "  to maximise the return;\n",
        "- An optimizer, which performs parameter updates based on our loss.\n",
        "\n",
        "Additional modules include a logger, a recorder (executes the policy in\n",
        "\"eval\" mode) and a target network updater. With all these components into\n",
        "place, it is easy to see how one could misplace or misuse one component in\n",
        "the training script. The trainer is there to orchestrate everything for you!\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "First let's write a helper function that will output an environment. As usual,\n",
        "the \"raw\" environment may be too simple to be used in practice and we'll need\n",
        "some data transformation to expose its output to the policy.\n",
        "\n",
        "We will be using five transforms:\n",
        "\n",
        "- :class:`~torchrl.envs.StepCounter` to count the number of steps in each trajectory;\n",
        "- :class:`~torchrl.envs.transforms.ToTensorImage` will convert a ``[W, H, C]`` uint8\n",
        "  tensor in a floating point tensor in the ``[0, 1]`` space with shape\n",
        "  ``[C, W, H]``;\n",
        "- :class:`~torchrl.envs.transforms.RewardScaling` to reduce the scale of the return;\n",
        "- :class:`~torchrl.envs.transforms.GrayScale` will turn our image into grayscale;\n",
        "- :class:`~torchrl.envs.transforms.Resize` will resize the image in a 64x64 format;\n",
        "- :class:`~torchrl.envs.transforms.CatFrames` will concatenate an arbitrary number of\n",
        "  successive frames (``N=4``) in a single tensor along the channel dimension.\n",
        "  This is useful as a single image does not carry information about the\n",
        "  motion of the cartpole. Some memory about past observations and actions\n",
        "  is needed, either via a recurrent neural network or using a stack of\n",
        "  frames.\n",
        "- :class:`~torchrl.envs.transforms.ObservationNorm` which will normalize our observations\n",
        "  given some custom summary statistics.\n",
        "\n",
        "In practice, our environment builder has two arguments:\n",
        "\n",
        "- ``parallel``: determines whether multiple environments have to be run in\n",
        "  parallel. We stack the transforms after the\n",
        "  :class:`~torchrl.envs.ParallelEnv` to take advantage\n",
        "  of vectorization of the operations on device, although this would\n",
        "  technically work with every single environment attached to its own set of\n",
        "  transforms.\n",
        "- ``obs_norm_sd`` will contain the normalizing constants for\n",
        "  the :class:`~torchrl.envs.ObservationNorm` transform.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RQC_CcaW7wiO"
      },
      "outputs": [],
      "source": [
        "num_workers = 1\n",
        "\n",
        "def make_env(\n",
        "    parallel=False,\n",
        "    obs_norm_sd=None,\n",
        "):\n",
        "    device = \"cuda\"\n",
        "    if obs_norm_sd is None:\n",
        "        obs_norm_sd = {\"standard_normal\": True}\n",
        "    if parallel:\n",
        "        base_env = ParallelEnv(\n",
        "            num_workers,\n",
        "            EnvCreator(\n",
        "                lambda: GymEnv(\n",
        "                    \"MountainCarContinuous-v0\",\n",
        "                    from_pixels=True,\n",
        "                    pixels_only=True,\n",
        "                    device=device,\n",
        "                )\n",
        "            ),\n",
        "        )\n",
        "    else:\n",
        "        base_env = GymEnv(\n",
        "            \"MountainCarContinuous-v0\",\n",
        "            from_pixels=True,\n",
        "            pixels_only=True,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    if parallel:\n",
        "        default_dict = {\n",
        "            \"belief\": UnboundedContinuousTensorSpec(shape=(num_workers, 200)),\n",
        "            \"state\": UnboundedContinuousTensorSpec(shape=(num_workers, 200)),\n",
        "        }\n",
        "    else:\n",
        "        default_dict = {\n",
        "            \"belief\": UnboundedContinuousTensorSpec(shape=(200, )),\n",
        "            \"state\": UnboundedContinuousTensorSpec(shape=(num_workers, 200)),\n",
        "        }\n",
        "\n",
        "    env = TransformedEnv(\n",
        "        base_env,\n",
        "        Compose(\n",
        "            StepCounter(),  # to count the steps of each trajectory\n",
        "            ToTensorImage(),\n",
        "            RewardScaling(loc=0.0, scale=0.1),  # TODO ???\n",
        "            GrayScale(),\n",
        "            Resize(64, 64),\n",
        "            FrameSkipTransform(2),\n",
        "            #CatFrames(4, in_keys=[\"pixels\"], dim=-3),\n",
        "            TensorDictPrimer(random=False, default_value=0, **default_dict),\n",
        "            ObservationNorm(in_keys=[\"pixels\"], **obs_norm_sd),\n",
        "        ),\n",
        "    )\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whA4GkcI7wiO"
      },
      "source": [
        "### Compute normalizing constants\n",
        "\n",
        "To normalize images, we don't want to normalize each pixel independently\n",
        "with a full ``[C, W, H]`` normalizing mask, but with simpler ``[C, 1, 1]``\n",
        "shaped set of normalizing constants (loc and scale parameters).\n",
        "We will be using the ``reduce_dim`` argument\n",
        "of :meth:`~torchrl.envs.ObservationNorm.init_stats` to instruct which\n",
        "dimensions must be reduced, and the ``keep_dims`` parameter to ensure that\n",
        "not all dimensions disappear in the process:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J5WxUZyu7wiO"
      },
      "outputs": [],
      "source": [
        "def get_norm_stats():\n",
        "    test_env = make_env()\n",
        "    test_env.transform[-1].init_stats(\n",
        "        num_iter=1000, cat_dim=0, reduce_dim=[-1, -2, -4], keep_dims=(-1, -2)\n",
        "    )\n",
        "    obs_norm_sd = test_env.transform[-1].state_dict()\n",
        "    # let's check that normalizing constants have a size of ``[C, 1, 1]`` where\n",
        "    # ``C=4`` (because of :class:`~torchrl.envs.CatFrames`).\n",
        "    print(\"state dict of the observation norm:\", obs_norm_sd)\n",
        "    test_env.close()\n",
        "    return obs_norm_sd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oizmexjh7wiP"
      },
      "source": [
        "## Building the model (MPC Dreamer)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ahG2cU6ta6gX"
      },
      "outputs": [],
      "source": [
        "class StatefulObsEncoder(nn.Module):\n",
        "  \"\"\"\n",
        "  ObsEncoder class of torchrl extended with GRU memory cell\n",
        "  \"\"\"\n",
        "  def __init__(self, encoded_dim, state_dim):\n",
        "      super(StatefulObsEncoder, self).__init__()\n",
        "      self.encoder = ObsEncoder()\n",
        "      self.memory_cell = nn.GRUCell(encoded_dim, state_dim)\n",
        "      self.encoded_dim = encoded_dim\n",
        "      self.state_dim = state_dim\n",
        "\n",
        "  def forward(self, observation, state):\n",
        "      encoded = self.encoder(observation)\n",
        "      encoded_shape = encoded.shape\n",
        "\n",
        "      if len(encoded_shape) == 3:\n",
        "        encoded = encoded.reshape(-1, self.encoded_dim)\n",
        "        state = state.reshape(-1, self.state_dim)\n",
        "        new_state = self.memory_cell(encoded, state)\n",
        "        new_state = new_state.reshape((*encoded_shape[:-1], self.state_dim))\n",
        "        encoded = encoded.reshape(encoded_shape)\n",
        "      else:\n",
        "        new_state = self.memory_cell(encoded, state)\n",
        "\n",
        "      return new_state, encoded\n",
        "\n",
        "class ObsEncoderWithTarget(nn.Module):\n",
        "  \"\"\"\n",
        "  Observation encoder class wrapper\n",
        "  Adds a target encoder, which is updated slowly\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, encoded_dim, state_dim):\n",
        "    super(ObsEncoderWithTarget, self).__init__()\n",
        "    self.encoder = StatefulObsEncoder(encoded_dim, state_dim)\n",
        "    self.target_encoder = copy.deepcopy(self.encoder)\n",
        "\n",
        "    for param in self.target_encoder.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self, observation, state):\n",
        "    return self.encoder(observation, state)\n",
        "\n",
        "  def forward_target(self, observation, state):\n",
        "    with torch.no_grad():\n",
        "      return self.target_encoder(observation, state)\n",
        "\n",
        "  def update_target(self, momentum: float = 0.99):\n",
        "      with torch.no_grad():\n",
        "          # use momentum to update the EMA encoder\n",
        "          for param_q, param_k in zip(\n",
        "              self.encoder.parameters(), self.target_encoder.parameters()\n",
        "          ):\n",
        "              param_k.data.mul_(momentum).add_((1.-momentum) * param_q.detach().data)\n",
        "\n",
        "          for param_q, param_k in zip(\n",
        "              self.memory_cell.parameters(), self.target_memory_cell.parameters()\n",
        "          ):\n",
        "              param_k.data.mul_(momentum).add_((1.-momentum) * param_q.detach().data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "E2ue4v8nYx77"
      },
      "outputs": [],
      "source": [
        "class Predictor(nn.Module):\n",
        "  \"\"\"\n",
        "  Predictor class\n",
        "  Takes encoded observation (state) as input and tries to predict the next\n",
        "\n",
        "  cell   default='gru'\n",
        "  action_dim\n",
        "  state_dim\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, cell, action_dim, state_dim):\n",
        "    super(Predictor, self).__init__()\n",
        "    if cell == 'gru':\n",
        "      self.cell = nn.GRUCell(action_dim, state_dim)\n",
        "    else:\n",
        "      raise NotImplementedError()\n",
        "\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    predicted_state = self.cell(action, state)\n",
        "    return predicted_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2vhGXGpTshhM"
      },
      "outputs": [],
      "source": [
        "class GRURollout(TensorDictModuleBase):\n",
        "    \"\"\"Rollout the RSSM network.\n",
        "\n",
        "    Given a set of encoded observations and actions, this module will rollout the RSSM network to compute all the intermediate\n",
        "    states and beliefs.\n",
        "    The previous posterior is used as the prior for the next time step.\n",
        "    The forward method returns a stack of all intermediate states and beliefs.\n",
        "\n",
        "    Reference: https://arxiv.org/abs/1811.04551\n",
        "\n",
        "    Args:\n",
        "        rssm_prior (TensorDictModule): Prior network.\n",
        "        rssm_posterior (TensorDictModule): Posterior network.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder: TensorDictModule, transition_model: TensorDictModule):\n",
        "        super().__init__()\n",
        "        _module = TensorDictSequential(encoder, transition_model)\n",
        "        self.in_keys = _module.in_keys\n",
        "        self.out_keys = _module.out_keys\n",
        "        self.encoder = encoder\n",
        "        self.transition_model = transition_model\n",
        "\n",
        "    def forward(self, tensordict):\n",
        "        \"\"\"Runs a rollout of simulated transitions in the latent space given a sequence of actions and environment observations.\n",
        "\n",
        "        The rollout requires a belief and posterior state primer.\n",
        "\n",
        "        At each step, two probability distributions are built and sampled from:\n",
        "        - A prior distribution p(s_{t+1} | s_t, a_t, b_t) where b_t is a\n",
        "            deterministic transform of the form b_t(s_{t-1}, a_{t-1}). The\n",
        "            previous state s_t is sampled according to the posterior\n",
        "            distribution (see below), creating a chain of posterior-to-priors\n",
        "            that accumulates evidence to compute a prior distribution over\n",
        "            the current event distribution:\n",
        "            p(s_{t+1} s_t | o_t, a_t, s_{t-1}, a_{t-1}) = p(s_{t+1} | s_t, a_t, b_t) q(s_t | b_t, o_t)\n",
        "\n",
        "        - A posterior distribution of the form q(s_{t+1} | b_{t+1}, o_{t+1})\n",
        "            which amends to q(s_{t+1} | s_t, a_t, o_{t+1})\n",
        "\n",
        "        \"\"\"\n",
        "        tensordict_out = []\n",
        "        *batch, time_steps = tensordict.shape\n",
        "\n",
        "        #update_values = tensordict.exclude(*self.out_keys).unbind(-1)\n",
        "        update_values = tensordict.unbind(-1)\n",
        "        _tensordict = update_values[0]\n",
        "        for t in range(time_steps):\n",
        "            # samples according to p(s_{t+1} | s_t, a_t, b_t)\n",
        "            # [\"state\", \"belief\", \"action\"] -> [(\"next\", \"prior_mean\"), (\"next\", \"prior_std\"), \"_\", (\"next\", \"belief\")]\n",
        "            #with timeit(\"rollout/time-encoder\"):\n",
        "            self.encoder(_tensordict)\n",
        "\n",
        "            # samples according to p(s_{t+1} | s_t, a_t, o_{t+1}) = p(s_t | b_t, o_t)\n",
        "            # [(\"next\", \"belief\"), (\"next\", \"encoded_latents\")] -> [(\"next\", \"posterior_mean\"), (\"next\", \"posterior_std\"), (\"next\", \"state\")]\n",
        "            #with timeit(\"rollout/time-transition-model\"):\n",
        "            self.transition_model(_tensordict)\n",
        "\n",
        "            tensordict_out.append(_tensordict)\n",
        "            if t < time_steps - 1:\n",
        "                _tensordict = step_mdp(\n",
        "                    _tensordict.select(*self.out_keys, strict=False), keep_other=False\n",
        "                )\n",
        "                _tensordict = update_values[t + 1].update(_tensordict)\n",
        "\n",
        "        return torch.stack(tensordict_out, tensordict.ndim - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ObsDecoder0(ObsDecoder):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        \n",
        "    def forward(self, encoded):\n",
        "        latent = self.state_to_latent(encoded)\n",
        "        *batch_sizes, D = latent.shape\n",
        "        latent = latent.view(-1, D, 1, 1)\n",
        "        obs_decoded = self.decoder(latent)\n",
        "        _, C, H, W = obs_decoded.shape\n",
        "        obs_decoded = obs_decoded.view(*batch_sizes, C, H, W)\n",
        "        return obs_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ViK7G97xqBgT"
      },
      "outputs": [],
      "source": [
        "class WorldModel(nn.Module):\n",
        "  \"\"\"\n",
        "  World Model class\n",
        "\n",
        "  encoder             - CNN + GRU\n",
        "  transition model    - GRU\n",
        "  reward model        - MLP\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, encoder, decoder, transition_model, reward_model):\n",
        "    super(WorldModel, self).__init__()\n",
        "    self.world_model = GRURollout(\n",
        "        transition_model = SafeModule(\n",
        "            transition_model,\n",
        "            in_keys=[\"state\", \"action\"],\n",
        "            out_keys=[(\"next\", \"belief\")],\n",
        "        ),\n",
        "        encoder = SafeModule(\n",
        "            encoder,\n",
        "            in_keys=[(\"next\", \"pixels\"), (\"next\", \"belief\")],\n",
        "            out_keys=[(\"next\", \"state\"), \"_\"],\n",
        "        ),\n",
        "    )\n",
        "    \n",
        "    self.decoder = SafeProbabilisticTensorDictSequential(\n",
        "        SafeModule(\n",
        "            decoder,\n",
        "            in_keys=[(\"next\", \"state\")],\n",
        "            out_keys=[(\"next\", \"loc\")]\n",
        "        ),\n",
        "        SafeProbabilisticModule(\n",
        "            in_keys=[(\"next\", \"loc\")],\n",
        "            out_keys=[(\"next\", \"reco_pixels\")],\n",
        "            distribution_class=IndependentNormal,\n",
        "            distribution_kwargs={\"scale\": 1.0, \"event_dim\": 3},\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "    self.target_encoder = SafeModule(\n",
        "            encoder.target_encoder,\n",
        "            in_keys=[(\"next\", \"pixels\"), (\"next\", \"belief\")],\n",
        "            out_keys=[(\"next\", \"state_target\"), \"_\"]\n",
        "    )\n",
        "\n",
        "    self.reward_model = SafeProbabilisticTensorDictSequential(\n",
        "        SafeModule(\n",
        "            reward_model,\n",
        "            in_keys=[(\"next\", \"state\")],\n",
        "            out_keys=[(\"next\", \"loc\")],\n",
        "        ),\n",
        "        SafeProbabilisticModule(\n",
        "            in_keys=[(\"next\", \"loc\")],\n",
        "            out_keys=[(\"next\", \"reward\")],\n",
        "            distribution_class=IndependentNormal,\n",
        "            distribution_kwargs={\"scale\": 1.0, \"event_dim\": 1},\n",
        "        ),\n",
        "    )\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "4CJAclg8c9EU"
      },
      "outputs": [],
      "source": [
        "encoded_dim = 1024\n",
        "state_dim = 200\n",
        "action_dim = 1\n",
        "\n",
        "mlp_depth = 3\n",
        "mlp_dims = 200\n",
        "activation = torch.nn.SiLU\n",
        "\n",
        "def make_model(dummy_env):\n",
        "  encoder = ObsEncoderWithTarget(encoded_dim, state_dim)\n",
        "  decoder = ObsDecoder0()\n",
        "  transition = Predictor('gru', action_dim, state_dim)\n",
        "  reward_model = MLP(out_features=1, depth=mlp_depth, num_cells=mlp_dims, activation_class=activation)\n",
        "\n",
        "  return WorldModel(encoder, decoder, transition, reward_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M5X7NJ-peE7m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "state dict of the observation norm: OrderedDict([('standard_normal', tensor(True, device='cuda:0')), ('loc', tensor([[[0.9931]]], device='cuda:0')), ('scale', tensor([[[0.0505]]], device='cuda:0'))])\n",
            "stats:  OrderedDict([('standard_normal', tensor(True, device='cuda:0')), ('loc', tensor([[[0.9931]]], device='cuda:0')), ('scale', tensor([[[0.0505]]], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "stats = get_norm_stats()\n",
        "print(\"stats: \", stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOm9Qh3USq2Z",
        "outputId": "c1b7fde1-223a-40fd-c15f-a29eef04f242"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "test_env = make_env(parallel = True, obs_norm_sd=stats)\n",
        "wm = make_model(test_env).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6wWejNCULNA",
        "outputId": "87077748-7cc2-4e5c-9f06-c4caad4e1d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([1, 10]),\n",
            "            device=cuda,\n",
            "            is_shared=True),\n",
            "        pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([1, 10]),\n",
            "    device=cuda,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "rollout = test_env.rollout(max_steps=10)\n",
        "print(rollout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGKAe5qlXyFO",
        "outputId": "613a2f8e-98e7-4ec2-abf9-f1b455f4c26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([1, 10]),\n",
            "            device=cuda,\n",
            "            is_shared=True),\n",
            "        pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([1, 10]),\n",
            "    device=cuda,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "world_model_td = wm.world_model(rollout)\n",
        "print(world_model_td)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECHKqLJVYcaD",
        "outputId": "1b3260f3-5730-42ef-92c6-b32d5a23e9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                loc: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([1, 10]),\n",
            "            device=cuda,\n",
            "            is_shared=True),\n",
            "        pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([1, 10]),\n",
            "    device=cuda,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "with_rewards = wm.reward_model(world_model_td)\n",
        "print(with_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-rTZiuPkx5E",
        "outputId": "c3187610-9466-4555-8cd8-7109b591a1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                loc: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_target: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([1, 10]),\n",
            "            device=cuda,\n",
            "            is_shared=True),\n",
            "        pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([1, 10]),\n",
            "    device=cuda,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "with_targets = wm.target_encoder(with_rewards)\n",
        "print(with_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                belief: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                done: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                loc: Tensor(shape=torch.Size([1, 10, 3, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reco_pixels: Tensor(shape=torch.Size([1, 10, 3, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                reward: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                state_target: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "                step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "                terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "                truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "            batch_size=torch.Size([1, 10]),\n",
            "            device=cuda,\n",
            "            is_shared=True),\n",
            "        pixels: Tensor(shape=torch.Size([1, 10, 1, 64, 64]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state: Tensor(shape=torch.Size([1, 10, 200]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1, 10, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([1, 10]),\n",
            "    device=cuda,\n",
            "    is_shared=True)\n"
          ]
        }
      ],
      "source": [
        "with_decoded = wm.decoder(with_targets)\n",
        "print(with_decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A-4Wijm7wiP"
      },
      "source": [
        "## Collecting and storing data\n",
        "\n",
        "### Replay buffers\n",
        "\n",
        "Replay buffers play a central role in off-policy RL sota-implementations such as DQN.\n",
        "They constitute the dataset we will be sampling from during training.\n",
        "\n",
        "Here, we will use a regular sampling strategy, although a prioritized RB\n",
        "could improve the performance significantly.\n",
        "\n",
        "We place the storage on disk using\n",
        ":class:`~torchrl.data.replay_buffers.storages.LazyMemmapStorage` class. This\n",
        "storage is created in a lazy manner: it will only be instantiated once the\n",
        "first batch of data is passed to it.\n",
        "\n",
        "The only requirement of this storage is that the data passed to it at write\n",
        "time must always have the same shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SkfneQTv7wiP"
      },
      "outputs": [],
      "source": [
        "def get_replay_buffer(buffer_size, n_optim, batch_size):\n",
        "    replay_buffer = TensorDictReplayBuffer(\n",
        "        batch_size=batch_size,\n",
        "        storage=LazyMemmapStorage(buffer_size),\n",
        "        prefetch=n_optim,\n",
        "    )\n",
        "    return replay_buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Zo7AyZ7wiP"
      },
      "source": [
        "### Data collector\n",
        "\n",
        "As in [PPO](https://pytorch.org/rl/tutorials/coding_ppo.html) and\n",
        "[DDPG](https://pytorch.org/rl/tutorials/coding_ddpg.html), we will be using\n",
        "a data collector as a dataloader in the outer loop.\n",
        "\n",
        "We choose the following configuration: we will be running a series of\n",
        "parallel environments synchronously in parallel in different collectors,\n",
        "themselves running in parallel but asynchronously.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This feature is only available when running the code within the \"spawn\"\n",
        "  start method of python multiprocessing library. If this tutorial is run\n",
        "  directly as a script (thereby using the \"fork\" method) we will be using\n",
        "  a regular :class:`~torchrl.collectors.SyncDataCollector`.</p></div>\n",
        "\n",
        "The advantage of this configuration is that we can balance the amount of\n",
        "compute that is executed in batch with what we want to be executed\n",
        "asynchronously. We encourage the reader to experiment how the collection\n",
        "speed is impacted by modifying the number of collectors (ie the number of\n",
        "environment constructors passed to the collector) and the number of\n",
        "environment executed in parallel in each collector (controlled by the\n",
        "``num_workers`` hyperparameter).\n",
        "\n",
        "Collector's devices are fully parametrizable through the ``device`` (general),\n",
        "``policy_device``, ``env_device`` and ``storing_device`` arguments.\n",
        "The ``storing_device`` argument will modify the\n",
        "location of the data being collected: if the batches that we are gathering\n",
        "have a considerable size, we may want to store them on a different location\n",
        "than the device where the computation is happening. For asynchronous data\n",
        "collectors such as ours, different storing devices mean that the data that\n",
        "we collect won't sit on the same device each time, which is something that\n",
        "out training loop must account for. For simplicity, we set the devices to\n",
        "the same value for all sub-collectors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "RKqDzcMy7wiP"
      },
      "outputs": [],
      "source": [
        "def get_collector(\n",
        "    stats,\n",
        "    num_collectors,\n",
        "    actor_explore,\n",
        "    frames_per_batch,\n",
        "    total_frames,\n",
        "    device,\n",
        "):\n",
        "    if actor_explore is None:\n",
        "        actor_explore = RandomPolicy(make_env(parallel=True, obs_norm_sd=stats).action_spec)\n",
        "    \n",
        "    cls = MultiaSyncDataCollector\n",
        "    env_arg = [make_env(parallel=True, obs_norm_sd=stats)] * num_collectors\n",
        "    data_collector = cls(\n",
        "        env_arg,\n",
        "        policy=actor_explore,\n",
        "        frames_per_batch=frames_per_batch,\n",
        "        total_frames=total_frames,\n",
        "        # this is the default behaviour: the collector runs in ``\"random\"`` (or explorative) mode\n",
        "        exploration_type=ExplorationType.RANDOM,\n",
        "        # We set the all the devices to be identical. Below is an example of\n",
        "        # heterogeneous devices\n",
        "        device=device,\n",
        "        storing_device=device,\n",
        "        split_trajs=False,\n",
        "    )\n",
        "    return data_collector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVrU9aCL7wiQ"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "Building our loss function is straightforward: we only need to provide\n",
        "the model and a bunch of hyperparameters to the DQNLoss class.\n",
        "\n",
        "### Target parameters\n",
        "\n",
        "Many off-policy RL sota-implementations use the concept of \"target parameters\" when it\n",
        "comes to estimate the value of the next state or state-action pair.\n",
        "The target parameters are lagged copies of the model parameters. Because\n",
        "their predictions mismatch those of the current model configuration, they\n",
        "help learning by putting a pessimistic bound on the value being estimated.\n",
        "This is a powerful trick (known as \"Double Q-Learning\") that is ubiquitous\n",
        "in similar sota-implementations.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "nDir22X37wiQ"
      },
      "outputs": [],
      "source": [
        "class ModelLoss(LossModule):\n",
        "    \"\"\"\n",
        "    Dreamer Model Loss.\n",
        "    \"\"\"\n",
        "\n",
        "    @dataclass\n",
        "    class _AcceptedKeys:\n",
        "        \"\"\"\n",
        "        Maintains default values for all configurable tensordict keys.\n",
        "        \"\"\"\n",
        "\n",
        "        reward: NestedKey = \"reward\"\n",
        "        true_reward: NestedKey = \"true_reward\"\n",
        "        prior: NestedKey = \"prior_logits\"\n",
        "        posterior: NestedKey = \"posterior_logits\"\n",
        "        pixels: NestedKey = \"pixels\"\n",
        "        reco_pixels: NestedKey = \"reco_pixels\"\n",
        "\n",
        "    default_keys = _AcceptedKeys()\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        world_model: TensorDictModule,\n",
        "        *,\n",
        "        lambda_distance: float = 1.0,\n",
        "        lambda_reco: float = 1.0,\n",
        "        lambda_reward: float = 1.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.world_model = world_model\n",
        "        self.lambda_distance = lambda_distance\n",
        "        self.lambda_reward = lambda_reward\n",
        "        self.lambda_reco = lambda_reco\n",
        "\n",
        "    def _forward_value_estimator_keys(self, **kwargs) -> None:\n",
        "        pass\n",
        "\n",
        "    def forward(self, tensordict: TensorDict) -> torch.Tensor:\n",
        "        \n",
        "        tensordict = tensordict.copy()\n",
        "        tensordict.rename_key_(\n",
        "            (\"next\", self.tensor_keys.reward),\n",
        "            (\"next\", self.tensor_keys.true_reward),\n",
        "        )\n",
        "        tensordict = self.world_model.world_model(tensordict)\n",
        "        tensordict = self.world_model.target_encoder(tensordict)\n",
        "        tensordict = self.world_model.decoder(tensordict)\n",
        "        tensordict = self.world_model.reward_model(tensordict)\n",
        "\n",
        "        # latent distance loss\n",
        "        latents = tensordict.get((\"next\", \"state\")).detach()\n",
        "        targets = tensordict.get((\"next\", \"state_target\"))\n",
        "        latent_distance_loss = torch.nn.MSELoss()(targets, latents).mean()\n",
        "        \n",
        "        # reconstruction loss\n",
        "        dist = self.world_model.decoder.get_dist(tensordict)\n",
        "        reco_loss = -dist.log_prob(tensordict.get((\"next\", self.tensor_keys.pixels)))\n",
        "        reco_loss = (reco_loss / (64 * 64)).mean()\n",
        "\n",
        "        # reward predictor loss\n",
        "        dist = self.world_model.reward_model.get_dist(tensordict)\n",
        "        reward_loss = -dist.log_prob(tensordict.get((\"next\", self.tensor_keys.true_reward))).mean()\n",
        "\n",
        "        return TensorDict(\n",
        "                {\n",
        "                    \"loss_model_distance\": self.lambda_distance * latent_distance_loss,\n",
        "                    \"loss_model_reco\": self.lambda_reco * reco_loss,\n",
        "                    \"loss_model_reward\": self.lambda_reward * reward_loss,\n",
        "                },\n",
        "                [],\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_740PR97wiQ"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Let's start with our hyperparameters. The following setting should work well\n",
        "in practice, and the performance of the algorithm should hopefully not be\n",
        "too sensitive to slight variations of these.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "WQk1PuBv7wiQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "print(is_fork)\n",
        "print(torch.device(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "2yOfJITj7wiQ"
      },
      "outputs": [],
      "source": [
        "# the learning rate of the optimizer\n",
        "lr = 3e-4\n",
        "# weight decay\n",
        "wd = 1e-5\n",
        "# the beta parameters of Adam\n",
        "betas = (0.9, 0.999)\n",
        "# Optimization steps per batch collected (aka UPD or updates per data)\n",
        "n_optim = 8\n",
        "\n",
        "gamma = 0.99\n",
        "tau = 0.02  # Smooth target network update decay parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "F0UVYDOO7wiQ"
      },
      "outputs": [],
      "source": [
        "total_frames = 1000*32  # 500000\n",
        "init_random_frames = 100  # 1000\n",
        "frames_per_batch = 32  # 128\n",
        "batch_size = 32  # 256\n",
        "buffer_size = min(total_frames, 100000)\n",
        "num_workers = 1  # 8\n",
        "num_collectors = 1  # 4\n",
        "eps_greedy_val = 0.1\n",
        "eps_greedy_val_env = 0.005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clunEO7o7wiU"
      },
      "source": [
        "## Building a Trainer\n",
        "\n",
        "TorchRL's :class:`~torchrl.trainers.Trainer` class constructor takes the\n",
        "following keyword-only arguments:\n",
        "\n",
        "- ``collector``\n",
        "- ``loss_module``\n",
        "- ``optimizer``\n",
        "- ``logger``: A logger can be\n",
        "- ``total_frames``: this parameter defines the lifespan of the trainer.\n",
        "- ``frame_skip``: when a frame-skip is used, the collector must be made\n",
        "  aware of it in order to accurately count the number of frames\n",
        "  collected etc. Making the trainer aware of this parameter is not\n",
        "  mandatory but helps to have a fairer comparison between settings where\n",
        "  the total number of frames (budget) is fixed but the frame-skip is\n",
        "  variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "pSbqn4zp7wiU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "#stats = get_norm_stats()\n",
        "test_env = make_env(parallel=False, obs_norm_sd=stats)\n",
        "# Get model\n",
        "world_model = make_model(test_env)\n",
        "loss_module = ModelLoss(world_model=world_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_wrapper_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_space` for environment variables or `env.get_wrapper_attr('reward_space')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "collector = get_collector(\n",
        "    stats=stats,\n",
        "    num_collectors=1,\n",
        "    actor_explore=None, # we don't use actor yet\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_493808/351325182.py:7: UserWarning: log dir: /tmp/tmp2o60o6gx/world_model_cbe0c8f2-fd90-11ee-a26b-0242ac110002\n",
            "  warnings.warn(f\"log dir: {logger.experiment.log_dir}\")\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    loss_module.parameters(), lr=lr, weight_decay=wd, betas=betas\n",
        ")\n",
        "exp_name = f\"world_model_{uuid.uuid1()}\"\n",
        "tmpdir = tempfile.TemporaryDirectory()\n",
        "logger = CSVLogger(exp_name=exp_name, log_dir=tmpdir.name)\n",
        "warnings.warn(f\"log dir: {logger.experiment.log_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6crceKpg7wiV"
      },
      "source": [
        "We can control how often the scalars should be logged. Here we set this\n",
        "to a low value as our training loop is short:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "aZpE5Ejl7wiV"
      },
      "outputs": [],
      "source": [
        "log_interval = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    collector=collector,\n",
        "    total_frames=total_frames,\n",
        "    frame_skip=1,\n",
        "    loss_module=loss_module,\n",
        "    optimizer=optimizer,\n",
        "    logger=logger,\n",
        "    optim_steps_per_batch=n_optim,\n",
        "    log_interval=log_interval,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGDRGU_w7wiV"
      },
      "source": [
        "### Registering hooks\n",
        "\n",
        "Registering hooks can be achieved in two separate ways:\n",
        "\n",
        "- If the hook has it, the :meth:`~torchrl.trainers.TrainerHookBase.register`\n",
        "  method is the first choice. One just needs to provide the trainer as input\n",
        "  and the hook will be registered with a default name at a default location.\n",
        "  For some hooks, the registration can be quite complex: :class:`~torchrl.trainers.ReplayBufferTrainer`\n",
        "  requires 3 hooks (``extend``, ``sample`` and ``update_priority``) which\n",
        "  can be cumbersome to implement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "sX1YsrwG7wiV"
      },
      "outputs": [],
      "source": [
        "buffer_hook = ReplayBufferTrainer(\n",
        "    get_replay_buffer(buffer_size, n_optim, batch_size=batch_size),\n",
        "    flatten_tensordicts=True,\n",
        ")\n",
        "buffer_hook.register(trainer)\n",
        "# no weights in collector\n",
        "#weight_updater = UpdateWeights(collector, update_weights_interval=1) \n",
        "# weight_updater.register(trainer)\n",
        "\n",
        "# actor performance has no meaning here\n",
        "#recorder = Recorder(\n",
        "#    record_interval=100,  # log every 100 optimization steps\n",
        "#    record_frames=1000,  # maximum number of frames in the record\n",
        "#    frame_skip=1,\n",
        "#    policy_exploration=RandomPolicy(test_env.action_spec),\n",
        "#    environment=test_env,\n",
        "#    exploration_type=ExplorationType.MODE,\n",
        "#    log_keys=[(\"next\", \"reward\")],\n",
        "#    out_keys={(\"next\", \"reward\"): \"rewards\"},\n",
        "#    log_pbar=True,\n",
        "#)\n",
        "#recorder.register(trainer)\n",
        "\n",
        "#trainer.register_op(\"post_steps\", actor_explore[1].step, frames=frames_per_batch) # The exploration module epsilon factor is also annealed\n",
        "#trainer.register_op(\"post_optim\", target_net_updater.step)\n",
        "\n",
        "log_reward = LogReward(log_pbar=True)\n",
        "log_reward.register(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "7tjJ_dJ37wiV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A[W CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
            "r_training: -0.0076:   6%|▌         | 1824/32000 [10:58<3:01:32,  2.77it/s]\n",
            "r_training: -0.0057:  12%|█▏        | 3904/32000 [20:34<2:28:07,  3.16it/s]\n",
            "r_training: -0.0059:   1%|          | 384/32000 [07:14<9:56:30,  1.13s/it]\n",
            "[W CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
            "r_training: -0.0072:   3%|▎         | 1056/32000 [06:21<3:06:27,  2.77it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlAnHXYx7wiV"
      },
      "source": [
        "We can now quickly check the CSVs with the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QogRgzru7wiV"
      },
      "outputs": [],
      "source": [
        "def print_csv_files_in_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Find all CSV files in a folder and prints the first 10 lines of each file.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The relative path to the folder.\n",
        "\n",
        "    \"\"\"\n",
        "    csv_files = []\n",
        "    output_str = \"\"\n",
        "    for dirpath, _, filenames in os.walk(folder_path):\n",
        "        for file in filenames:\n",
        "            if file.endswith(\".csv\"):\n",
        "                csv_files.append(os.path.join(dirpath, file))\n",
        "    for csv_file in csv_files:\n",
        "        output_str += f\"File: {csv_file}\\n\"\n",
        "        with open(csv_file, \"r\") as f:\n",
        "            for i, line in enumerate(f):\n",
        "                if i == 10:\n",
        "                    break\n",
        "                output_str += line.strip() + \"\\n\"\n",
        "        output_str += \"\\n\"\n",
        "    print(output_str)\n",
        "\n",
        "\n",
        "print_csv_files_in_folder(logger.experiment.log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf3j1dBO7wiV"
      },
      "source": [
        "## Conclusion and possible improvements\n",
        "\n",
        "In this tutorial we have learned:\n",
        "\n",
        "- How to write a Trainer, including building its components and registering\n",
        "  them in the trainer;\n",
        "- How to code a DQN algorithm, including how to create a policy that picks\n",
        "  up the action with the highest value with\n",
        "  :class:`~torchrl.modules.QValueNetwork`;\n",
        "- How to build a multiprocessed data collector;\n",
        "\n",
        "Possible improvements to this tutorial could include:\n",
        "\n",
        "- A prioritized replay buffer could also be used. This will give a\n",
        "  higher priority to samples that have the worst value accuracy.\n",
        "  Learn more on the\n",
        "  [replay buffer section](https://pytorch.org/rl/reference/data.html#composable-replay-buffers)\n",
        "  of the documentation.\n",
        "- A distributional loss (see :class:`~torchrl.objectives.DistributionalDQNLoss`\n",
        "  for more information).\n",
        "- More fancy exploration techniques, such as :class:`~torchrl.modules.NoisyLinear` layers and such.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7dtGS61g3mW"
      },
      "outputs": [],
      "source": [
        "class ActorCritic(nn.Module):\n",
        "  \"\"\"\n",
        "  Actor critic module\n",
        "\n",
        "  policy_module\n",
        "  value_module\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, proof_environment)\n",
        "    # Define input/output distributions\n",
        "    input_shape = proof_environment.observation_spec[\"observation\"].shape\n",
        "    num_outputs = proof_environment.action_spec.shape[-1]\n",
        "    distribution_class = TanhNormal\n",
        "    distribution_kwargs = {\n",
        "        \"min\": proof_environment.action_spec.space.low,\n",
        "        \"max\": proof_environment.action_spec.space.high,\n",
        "        \"tanh_loc\": False,\n",
        "    }\n",
        "\n",
        "    # Define policy architecture\n",
        "    policy_mlp = MLP(\n",
        "        in_features=input_shape[-1],\n",
        "        activation_class=torch.nn.Tanh,\n",
        "        out_features=num_outputs,  # predict only loc\n",
        "        num_cells=[64, 64],\n",
        "    )\n",
        "    for layer in policy_mlp.modules():\n",
        "        if isinstance(layer, torch.nn.Linear):\n",
        "            torch.nn.init.orthogonal_(layer.weight, 1.0)\n",
        "            layer.bias.data.zero_()\n",
        "\n",
        "    # Add state-independent normal scale\n",
        "    policy_mlp = torch.nn.Sequential(\n",
        "        policy_mlp,\n",
        "        AddStateIndependentNormalScale(proof_environment.action_spec.shape[-1]),\n",
        "    )\n",
        "\n",
        "    # Add probabilistic sampling of the actions\n",
        "    self.policy_module = ProbabilisticActor(\n",
        "        TensorDictModule(\n",
        "            module=policy_mlp,\n",
        "            in_keys=[\"observation\"],\n",
        "            out_keys=[\"loc\", \"scale\"],\n",
        "        ),\n",
        "        in_keys=[\"loc\", \"scale\"],\n",
        "        spec=CompositeSpec(action=proof_environment.action_spec),\n",
        "        distribution_class=distribution_class,\n",
        "        distribution_kwargs=distribution_kwargs,\n",
        "        return_log_prob=True,\n",
        "        default_interaction_type=ExplorationType.RANDOM,\n",
        "    )\n",
        "\n",
        "    # Define value architecture\n",
        "    value_mlp = MLP(\n",
        "        in_features=input_shape[-1],\n",
        "        activation_class=torch.nn.Tanh,\n",
        "        out_features=1,\n",
        "        num_cells=[64, 64],\n",
        "    )\n",
        "    for layer in value_mlp.modules():\n",
        "        if isinstance(layer, torch.nn.Linear):\n",
        "            torch.nn.init.orthogonal_(layer.weight, 0.01)\n",
        "            layer.bias.data.zero_()\n",
        "\n",
        "    # Define value module\n",
        "    self.value_module = ValueOperator(\n",
        "        value_mlp,\n",
        "        in_keys=[\"observation\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULM6oNWpg7Ga"
      },
      "outputs": [],
      "source": [
        "class Plan2ExploreModule(nn.Module):\n",
        "\n",
        "  def __init__(self, reward_scale, use_log):\n",
        "    self._networks = [MLP(size, **config.expl_head)\n",
        "                      for _ in range(config.disag_models)]\n",
        "    self.use_log = use_log\n",
        "    self.reward_scale = reward_scale\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    state_action = torch.cat([state, action], dim=-1)\n",
        "    preds = [head(state_action).mode() for head in self._networks]\n",
        "    disagreement = torch.tensor(preds).std(0).mean(-1)\n",
        "\n",
        "    if self.use_log:\n",
        "      disagreement = torch.log(disagreement)\n",
        "\n",
        "    reward = self.reward_scale * self.intr_rewnorm(disagreement)[0]\n",
        "    #if self.config.expl_extr_scale:\n",
        "    #  reward += self.config.expl_extr_scale * self.extr_rewnorm(\n",
        "    #      self.reward(seq))[0]\n",
        "    return reward\n",
        "\n",
        "\n",
        "    class Plan2ExploreLoss():\n",
        "\n",
        "  def __init__(self, config, act_space, wm, tfstep, reward):\n",
        "\n",
        "\n",
        "\n",
        "  def _train_ensemble(self, inputs, targets):\n",
        "    if self.config.disag_offset:\n",
        "      targets = targets[:, self.config.disag_offset:]\n",
        "      inputs = inputs[:, :-self.config.disag_offset]\n",
        "    targets = tf.stop_gradient(targets)\n",
        "    inputs = tf.stop_gradient(inputs)\n",
        "    with tf.GradientTape() as tape:\n",
        "      preds = [head(inputs) for head in self._networks]\n",
        "      loss = -sum([pred.log_prob(targets).mean() for pred in preds])\n",
        "    metrics = self.opt(tape, loss, self._networks)\n",
        "    return metrics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
