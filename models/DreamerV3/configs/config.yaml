env:
  name: cheetah
  task: run
  seed: 0
  backend: dm_control
  frame_skip: 2
  from_pixels: True
  grayscale: False
  image_size : 64
  horizon: 500
  n_parallel_envs: 1
  device: cuda:0
 #   _target_: utils._default_device
 #   device: null

collector:
  total_frames: 5_000_000
  pretrain: 100
  init_random_frames: 5000
  frames_per_batch: 250
  device:
    _target_: utils._default_device
    device: null

optimization:
  grad_clip: 100
  world_model_lr: 3e-4
  actor_lr: 1e-4
  value_lr: 1e-4
  kl_scale: 0.8 # different from original impl. (kl_balance there)
  free_nats: 1.0
  optim_steps_per_batch: 10
  gamma: 0.99
  lmbda: 0.95
  imagination_horizon: 15
  compile: False
  compile_backend: inductor
  use_autocast: True

networks:
  exploration_noise: 0
  device:
    _target_: utils._default_device
    device: null
  state_dim: 32
  state_vars: 32
  rssm_hidden_dim: 200
  hidden_dim: 400
  activation: "elu"


replay_buffer: 
  batch_size: 2500
  buffer_size: 1000000
  batch_length: 50
  scratch_dir: null

logger:
  model_name: DreamerV2
  backend: wandb
  project: dreamer-v2
  exp_name: ${env.name}-${env.task}-${env.seed}
  mode: online
  # eval interval, in collection counts
  eval_iter: 100
  eval_rollout_steps: 500
  video: True
  enable_profiler: False


# added:
#   model_name: DreamerV1
#   